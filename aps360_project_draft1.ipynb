{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeNq3GwofOdZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torchvision.ops import RoIPool\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import cv2  # For image processing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Architecture"
      ],
      "metadata": {
        "id": "RXbhfw2Khj6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RPN(nn.Module):\n",
        "    def __init__(self, in_channels, num_anchors):\n",
        "        super(RPN, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, 512, kernel_size=3, padding=1)\n",
        "        self.cls_logits = nn.Conv2d(512, num_anchors * 2, kernel_size=1)  # Objectness score\n",
        "        self.bbox_pred = nn.Conv2d(512, num_anchors * 4, kernel_size=1)  # Bounding box regression\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.ReLU()(self.conv(x))\n",
        "        objectness = self.cls_logits(x)\n",
        "        bbox_regression = self.bbox_pred(x)\n",
        "        return objectness, bbox_regression\n",
        "\n",
        "\n",
        "class ObjectDetector(nn.Module):\n",
        "    def __init__(self, num_classes=2, num_anchors=9):\n",
        "        super(ObjectDetector, self).__init__()\n",
        "        self.backbone = models.vgg16(pretrained=True).features[:30]  # Use layers up to conv5_3\n",
        "        self.rpn = RPN(512, num_anchors)\n",
        "        self.roi_pool = RoIPool(output_size=(7, 7), spatial_scale=1/16)  # Adjust based on input size\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4096, num_classes),  # Classification\n",
        "            nn.Linear(4096, num_anchors * 4)  # Bounding box regression\n",
        "        )\n",
        "\n",
        "    def forward(self, images, proposals):\n",
        "        features = self.backbone(images)\n",
        "        objectness, bbox_regression = self.rpn(features)\n",
        "        pooled_rois = self.roi_pool(features, proposals)\n",
        "        pooled_rois_flat = pooled_rois.view(pooled_rois.size(0), -1)  # Flatten\n",
        "        fc_out = self.fc(pooled_rois_flat)\n",
        "        return objectness, bbox_regression, fc_out"
      ],
      "metadata": {
        "id": "HEJaG0NvhN7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IoU Loss Function"
      ],
      "metadata": {
        "id": "T8ZVCGeNjbW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def iou_loss(pred_boxes, target_boxes):\n",
        "    # pred_boxes and target_boxes should be of shape (N, 4) where N is number of boxes\n",
        "    inter_x1 = torch.max(pred_boxes[:, 0], target_boxes[:, 0])\n",
        "    inter_y1 = torch.max(pred_boxes[:, 1], target_boxes[:, 1])\n",
        "    inter_x2 = torch.min(pred_boxes[:, 2], target_boxes[:, 2])\n",
        "    inter_y2 = torch.min(pred_boxes[:, 3], target_boxes[:, 3])\n",
        "\n",
        "    inter_area = torch.clamp(inter_x2 - inter_x1, min=0) * torch.clamp(inter_y2 - inter_y1, min=0)\n",
        "    pred_area = (pred_boxes[:, 2] - pred_boxes[:, 0]) * (pred_boxes[:, 3] - pred_boxes[:, 1])\n",
        "    target_area = (target_boxes[:, 2] - target_boxes[:, 0]) * (target_boxes[:, 3] - target_boxes[:, 1])\n",
        "\n",
        "    union_area = pred_area + target_area - inter_area\n",
        "    iou = inter_area / (union_area + 1e-6)  # Add epsilon to avoid division by zero\n",
        "\n",
        "    return 1 - iou.mean()"
      ],
      "metadata": {
        "id": "3Ln1bA4hjcYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def non_max_suppression(boxes, scores, threshold=0.5):\n",
        "    if len(boxes) == 0:\n",
        "        return []\n",
        "\n",
        "    x1 = boxes[:, 0]\n",
        "    y1 = boxes[:, 1]\n",
        "    x2 = boxes[:, 2]\n",
        "    y2 = boxes[:, 3]\n",
        "\n",
        "    areas = (x2 - x1) * (y2 - y1)\n",
        "    order = scores.argsort()[::-1]\n",
        "\n",
        "    keep = []\n",
        "    while order.size > 0:\n",
        "        i = order[0]\n",
        "        keep.append(i)\n",
        "\n",
        "        xx1 = torch.max(x1[i], x1[order[1:]])\n",
        "        yy1 = torch.max(y1[i], y1[order[1:]])\n",
        "        xx2 = torch.min(x2[i], x2[order[1:]])\n",
        "        yy2 = torch.min(y2[i], y2[order[1:]])\n",
        "\n",
        "        w = torch.clamp(xx2 - xx1, min=0)\n",
        "        h = torch.clamp(yy2 - yy1, min=0)\n",
        "\n",
        "        inter = w * h\n",
        "        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
        "\n",
        "        order = order[1:][ovr <= threshold]\n",
        "\n",
        "    return keep"
      ],
      "metadata": {
        "id": "uu0b25TUkohu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proposal generator"
      ],
      "metadata": {
        "id": "I5NWOHOllp7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_proposals(objectness_scores, bbox_deltas, anchors, threshold=0.5):\n",
        "    scores = torch.sigmoid(objectness_scores)  # Apply sigmoid to get probabilities\n",
        "    filtered_indices = torch.where(scores > threshold)[0]\n",
        "\n",
        "    proposals = []\n",
        "    for idx in filtered_indices:\n",
        "        anchor = anchors[idx]\n",
        "        delta = bbox_deltas[idx]\n",
        "        proposal = anchor + delta\n",
        "        proposals.append(proposal)\n",
        "\n",
        "    return torch.stack(proposals)"
      ],
      "metadata": {
        "id": "UBVzF0R7lrPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "3Z8UCfvjhi8D"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MOH78UsAhifM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloader, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for images, targets in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass through the model\n",
        "            objectness, bbox_regression = model.rpn(model.backbone(images))\n",
        "\n",
        "            # Generate proposals\n",
        "            proposals = generate_proposals(objectness, bbox_regression, dataset.anchors)\n",
        "\n",
        "            # NMS to filter proposals\n",
        "            # Assuming the scores are the objectness scores from the RPN\n",
        "            keep_indices = non_max_suppression(proposals, objectness[keep_indices], threshold=0.5)\n",
        "            proposals = proposals[keep_indices]\n",
        "\n",
        "            # Run the proposals through the model\n",
        "            objectness, bbox_regression, fc_out = model(images, proposals)\n",
        "\n",
        "            # Assuming targets include labels and bounding boxes\n",
        "            class_loss = nn.CrossEntropyLoss()(fc_out, targets['labels'])\n",
        "            bbox_loss = iou_loss(bbox_regression, targets['boxes'])\n",
        "\n",
        "            loss = class_loss + bbox_loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}')"
      ],
      "metadata": {
        "id": "bs6sB3bEh1_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes:\n",
        " - Image dataset should have anchor boxes\n",
        " - RoI pooling takes (batch_index, x1, y1, x2, y2)\n",
        "  -"
      ],
      "metadata": {
        "id": "nyewMN9pmXFj"
      }
    }
  ]
}